{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout, LeakyReLU\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load your dataset\n",
    "data = pd.read_csv(r'C:\\Users\\BHARGAVI CHOWDARY\\Desktop\\PROJECT_ML\\diabetes_012_health_indicators_BRFSS2015.csv')\n",
    "\n",
    "# Separate features and labels\n",
    "X = data.drop(columns=['Diabetes_012'])  # Replace 'Diabetes_012' with your label column name\n",
    "y = data['Diabetes_012']\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Apply SMOTE to balance the classes in the training set\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Convert labels to categorical for multi-class classification\n",
    "y_train_res = tf.keras.utils.to_categorical(y_train_res, 3)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 3)\n",
    "\n",
    "# Define the Neural Network component with increased complexity\n",
    "def neural_network(input_shape):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = Dense(512)(inputs)  # Increased neurons\n",
    "    x = LeakyReLU(alpha=0.1)(x)  # Leaky ReLU activation\n",
    "    x = Dropout(0.1)(x)  # Reduced dropout\n",
    "    x = Dense(256)(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(128)(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(64)(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    return Model(inputs, x)\n",
    "\n",
    "# Define the Decision Forest layer\n",
    "def decision_forest_layer(x, num_trees=5, num_classes=3):\n",
    "    tree_outputs = []\n",
    "    for i in range(num_trees):\n",
    "        tree_output = Dense(num_classes, activation='softmax', name=f'tree_{i+1}')(x)\n",
    "        tree_outputs.append(tree_output)\n",
    "    output = tf.keras.layers.Average()(tree_outputs)\n",
    "    return output\n",
    "\n",
    "# Build the Deep Neural Decision Forest Model\n",
    "input_shape = (X_train.shape[1],)\n",
    "nn_model = neural_network(input_shape)\n",
    "decision_forest_output = decision_forest_layer(nn_model.output)\n",
    "\n",
    "# Create the final model\n",
    "model = Model(inputs=nn_model.input, outputs=decision_forest_output)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Set up callbacks for learning rate reduction and early stopping\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6, verbose=1)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True, verbose=1)\n",
    "\n",
    "# Train the model with increased epochs and batch size tuning\n",
    "history = model.fit(X_train_res, y_train_res, validation_data=(X_test, y_test), \n",
    "                    epochs=200, batch_size=32, callbacks=[reduce_lr, early_stopping])  # Increased epochs and adjusted batch size\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "\n",
    "# Generate predictions\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Classification report\n",
    "report = classification_report(y_true, y_pred_classes, target_names=['Class 0', 'Class 1', 'Class 2'])\n",
    "print(report)\n",
    "\n",
    "# Confusion matrix\n",
    "conf_matrix = confusion_matrix(y_true, y_pred_classes)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Class 0', 'Class 1', 'Class 2'], yticklabels=['Class 0', 'Class 1', 'Class 2'])\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Plotting training and validation accuracy/loss\n",
    "\n",
    "# Plot accuracy\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Model Accuracy')\n",
    "plt.show()\n",
    "\n",
    "# Plot loss\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Model Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
